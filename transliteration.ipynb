{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b6066d0",
   "metadata": {},
   "source": [
    "# website: https://pypi.org/project/ai4bharat-transliteration/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6defaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ai4bharat-transliteration==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909ebd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hp/election_analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import json\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c16bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': ['Assamese - অসমীয়া'],\n",
       " 'bn': ['Bangla - বাংলা'],\n",
       " 'brx': ['Boro - बड़ो'],\n",
       " 'gu': ['Gujarati - ગુજરાતી'],\n",
       " 'hi': ['Hindi - हिंदी'],\n",
       " 'kn': ['Kannada - ಕನ್ನಡ'],\n",
       " 'ks': ['Kashmiri - كٲشُر'],\n",
       " 'gom': ['Konkani Goan - कोंकणी'],\n",
       " 'mai': ['Maithili - मैथिली'],\n",
       " 'ml': ['Malayalam - മലയാളം'],\n",
       " 'mni': ['Manipuri - ꯃꯤꯇꯩꯂꯣꯟ'],\n",
       " 'mr': ['Marathi - मराठी'],\n",
       " 'ne': ['Nepali - नेपाली'],\n",
       " 'or': ['Oriya - ଓଡ଼ିଆ'],\n",
       " 'pa': ['Panjabi - ਪੰਜਾਬੀ'],\n",
       " 'sa': ['Sanskrit - संस्कृतम्'],\n",
       " 'sd': ['Sindhi - سنڌي'],\n",
       " 'si': ['Sinhala - සිංහල'],\n",
       " 'ta': ['Tamil - தமிழ்'],\n",
       " 'te': ['Telugu - తెలుగు'],\n",
       " 'ur': ['Urdu - اُردُو']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supported languages and their codes\n",
    "\n",
    "{'as': ['Assamese - অসমীয়া'],\n",
    " 'bn': ['Bangla - বাংলা'],\n",
    " 'brx': ['Boro - बड़ो'],\n",
    " 'gu': ['Gujarati - ગુજરાતી'],\n",
    " 'hi': ['Hindi - हिंदी'],\n",
    " 'kn': ['Kannada - ಕನ್ನಡ'],\n",
    " 'ks': ['Kashmiri - كٲشُر'],\n",
    " 'gom': ['Konkani Goan - कोंकणी'],\n",
    " 'mai': ['Maithili - मैथिली'],\n",
    " 'ml': ['Malayalam - മലയാളം'],\n",
    " 'mni': ['Manipuri - ꯃꯤꯇꯩꯂꯣꯟ'],\n",
    " 'mr': ['Marathi - मराठी'],\n",
    " 'ne': ['Nepali - नेपाली'],\n",
    " 'or': ['Oriya - ଓଡ଼ିଆ'],\n",
    " 'pa': ['Panjabi - ਪੰਜਾਬੀ'],\n",
    " 'sa': ['Sanskrit - संस्कृतम्'],\n",
    " 'sd': ['Sindhi - سنڌي'],\n",
    " 'si': ['Sinhala - සිංහල'],\n",
    " 'ta': ['Tamil - தமிழ்'],\n",
    " 'te': ['Telugu - తెలుగు'],\n",
    " 'ur': ['Urdu - اُردُو']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c17201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai4bharat.transliteration import XlitEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa0b2f",
   "metadata": {},
   "source": [
    "# English to regional language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee901b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file with data to convert\n",
    "# File should only contain columns that you want to convert/transliterate\n",
    "filename = '/home/hp/Downloads/20_Remaining State - Translation_Zila.xlsx'\n",
    "df_main = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f8cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary cleaning here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247b9914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 200.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# collecting words to translate (to be fed into transliteration model)\n",
    "\n",
    "words = []\n",
    "for i in tqdm(df_main.columns): #iterating on columns\n",
    "    i = str(i)\n",
    "    df_temp = df_main[df_main[i].notnull()][[i]].drop_duplicates() #drop duplicate rows\n",
    "    df_temp[i] = df_temp[i].apply(lambda x:x.lower().strip().split(' ')) #converting every word to lower and removing spaces\n",
    "    df_temp = df_temp.explode([i]) # converting list to rows\n",
    "    words.append(df_temp[i].unique().tolist()) # taking only unique from the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1039ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set([i for sublist in words for i in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92a33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dicts into RAM: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load transliteration object to ram\n",
    "engine = XlitEngine(\"hi\", beam_width=4, rescore=True) #'hi' stands for Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff6a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json of already converted names\n",
    "with open ('/home/hp/Downloads/eng_to_hin.json', \"r\") as file:\n",
    "    words_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3308045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90996\n"
     ]
    }
   ],
   "source": [
    "print(len(words_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f001e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 954/954 [01:27<00:00, 10.91it/s]\n"
     ]
    }
   ],
   "source": [
    "def transliteration(unique_words,words_dict):\n",
    "    converted_words = []\n",
    "    for i in tqdm(unique_words):\n",
    "        try:\n",
    "            converted_words.append(words_dict[i][0])\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "        i = i + ' '\n",
    "        temp = ''\n",
    "        converted_words_temp = ''\n",
    "        for letter in i: #check each letter if it is an alphabet\n",
    "            if(letter.isalpha()):\n",
    "                temp = temp + letter #string till we find alphabet\n",
    "            else:\n",
    "                try:\n",
    "                    try:\n",
    "                        converted_words_temp = converted_words_temp + words_dict[temp.strip()][0] + str(letter)\n",
    "                    except:\n",
    "                        #word not found in words_dict\n",
    "                        temp_eng2lang = engine.translit_word(temp.strip(), topk=1)\n",
    "                        words_dict[temp.strip()] = temp_eng2lang['hi'][0].replace('\\u200c','') # add word to dictinoary \n",
    "                        converted_words_temp = converted_words_temp + words_dict[temp.strip()] + str(letter)\n",
    "                except:\n",
    "                    #exceptional case: leave the word as it is\n",
    "                    converted_words_temp = converted_words_temp + str(letter)\n",
    "                temp = ''\n",
    "        converted_words.append(converted_words_temp.strip())\n",
    "    return converted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5836afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_words_dict = dict(zip(unique_words, converted_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac8bdbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 605.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df_main.columns):\n",
    "    df_main[str(i) + '_converted'] = df_main[str(i)].apply(lambda x:np.nan if(x!=x) else ' '.join([converted_words_dict[i] for i in x.lower().strip().split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f184fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the dictionary\n",
    "with open('eng_to_hin.json', \"w\") as outfile:\n",
    "    json.dump(words_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c925e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save converted file\n",
    "final_filename = filename.split('.')[0] + '_converted.' + filename.split('.')[1] \n",
    "df_main.to_excel(final_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9257e13",
   "metadata": {},
   "source": [
    "# Regional to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file with data to convert\n",
    "# File should only contain columns that you want to convert/transliterate\n",
    "filename = r'file.xlsx'\n",
    "\n",
    "df = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1992214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary cleaning here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = XlitEngine(src_script_type=\"indic\", beam_width=4, rescore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2753750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting words to translate (to be fed into transliteration model)\n",
    "\n",
    "words = []\n",
    "for i in tqdm(df_main.columns): #iterating on columns\n",
    "    i = str(i)\n",
    "    df_temp = df_main[df_main[i].notnull()][[i]].drop_duplicates() #drop duplicate rows\n",
    "    df_temp[i] = df_temp[i].apply(lambda x:x.lower().strip().split(' ')) #converting every word to lower and removing spaces\n",
    "    df_temp = df_temp.explode([i]) # converting list to rows\n",
    "    words.append(df_temp[i].unique().tolist()) # taking only unique from the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2129e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set([i for sublist in words for i in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json of already converted names\n",
    "with open ('hin_to_eng.json', \"r\") as file:\n",
    "    words_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c00dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in tqdm(l1):\n",
    "    try:\n",
    "        l.append(diss[i][0])\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    l.append(e.translit_word(i, lang_code=\"hi\", topk=1)[0])  # 'hi' language code for hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['hi'] = l1\n",
    "df1['eng'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = df1.set_index('hi')['eng'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6caac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(df.columns):\n",
    "    df[str(i) + '_converted'] = df[str(i)].apply(lambda x:np.nan if(x!=x) else ' '.join([my_dict[i] for i in x.lower().strip().split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8271353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save converted file\n",
    "df.to_excel(r'', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27452e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update new found words to existing dictionary\n",
    "new_dict = {**diss, **my_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the dictionary\n",
    "with open('hin_to_eng.json', \"w\") as outfile:\n",
    "    json.dump(new_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
